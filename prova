# create a r code for automatic sentinel 2 data download



# load required packages

library(rgdal)
library(raster)
library(rasterVis)
library(ggplot2)
library(gdalUtils)
library(RCurl)
library(stringr)
library(magrittr)
library(tidyverse)
library(geoknife)
library(spatstat)
library(repmis)
library(RStoolbox)
library(lubridate)



# define some function


# function to download the data from sentinel

sentinel_download <- function(lat, lon, start_date, end_date){
  # create a vector of dates
  dates <- seq(ymd(start), ymd(end), by = "1 day")
  dates_str <- as.character(dates)
  
  # create a vector of dates to download
  download_date <- vector()
  for (i in 1:length(dates)){
    # find out the doy
    doy <- as.numeric(format(dates[i], "%j"))

    # decide the download date based on doy
    if (doy > 1 & doy < 181){
      date_to_download <- dates_str[i]
      download_date <- c(download_date, date_to_download)
    }
  }
  
  # download the data
  for (i in 1:length(download_date)){
    # create a request
    request <- paste0("https://scihub.copernicus.eu/dhus/search?q=beginPosition:[", download_date[i], "T00:00:00.000Z%20TO%20", download_date[i], "T23:59:59.999Z]%20AND%20platformname:Sentinel-2%20AND%20footprint:\"Intersects(POLYGON((", lon, "%20", lat, ",%20", lon, "%20", lat, ",%20", lon, "%20", lat, ",%20", lon, "%20", lat, ",%20", lon, "%20", lat, ")))\"&rows=1&start=0&format=json")
    
    # do the request and get json file
    download_json <- getURL(request)
    download_json <- fromJSON(download_json)
    
    # extract the download link
    download_link <- download_json$entry[[1]]$link[[2]]$href
    download_link <- as.character(download_link)
    
    # download the data
    download_file <- download.file(download_link, basename(download_link), mode = "wb")
    
    # extract the zip file
    unzip(basename(download_link))
    
    # delete the zip file
    file.remove(basename(download_link))
  }
}



# function to crop the data into a smaller size

sentinel_crop <- function(file, lat, lon, crop_size){
  # load the file
  raster_file <- raster(file)
  
  # crop the file
  crop_file <- crop(raster_file, extent(c(lon - crop_size, lon + crop_size, lat - crop_size, lat + crop_size)))
  
  # return the file
  return(crop_file)
}



# function to convert the data into a single time series

sentinel_time_series <- function(path, output_name, lat, lon, start_date, end_date){
  # create a vector of dates
  dates <- seq(ymd(start_date), ymd(end_date), by = "1 day")
  dates_str <- as.character(dates)
  
  # create a vector of dates to download
  download_date <- vector()
  for (i in 1:length(dates)){
    # find out the doy
    doy <- as.numeric(format(dates[i], "%j"))

    # decide the download date based on doy
    if (doy > 1 & doy < 181){
      date_to_download <- dates_str[i]
      download_date <- c(download_date, date_to_download)
    }
  }
  
  # extract all the band file
  band_file <- vector()
  for (i in 1:length(download_date)){
    # create a file name
    file_name <- paste0("S2A_MSIL1C_", download_date[i], "_T18LPQ_N0206_R065_T32TMG_", download_date[i], ".SAFE/GRANULE/L1C_T32TMG_A002297_", download_date[i], "/IMG_DATA/T32TMG_20180", format(as.numeric(format(download_date[i], "%j")) + 1, width = 3, justify = "left"), "_B02_10m.jp2")
    
    # load the file and append to the band file
    band_file <- c(band_file, raster(file_name))
  }
  
  # crop the band file
  for (i in 1:length(band_file)){
    crop_band <- crop(band_file[i], extent(c(lon - 0.1, lon + 0.1, lat - 0.1, lat + 0.1)))
    band_file[i] <- crop_band
  }
  
  # convert the band file into a single time series
  time_series <- stack(band_file)
  
  # write the time series into a single file
  writeRaster(time_series, output_name)
}



# function to create a single NDVI time series

sentinel_NDVI_time_series <- function(path, output_name, lat, lon, start_date, end_date){
  # create a vector of dates
  dates <- seq(ymd(start_date), ymd(end_date), by = "1 day")
  dates_str <- as.character(dates)
  
  # create a vector of dates to download
  download_date <- vector()
  for (i in 1:length(dates)){
    # find out the doy
    doy <- as.numeric(format(dates[i], "%j"))

    # decide the download date based on doy
    if (doy > 1 & doy < 181){
      date_to_download <- dates_str[i]
      download_date <- c(download_date, date_to_download)
    }
  }
  
  # extract all the band file
  band_file <- vector()
  for (i in 1:length(download_date)){
    # create a file name
    file_name <- paste0("S2A_MSIL1C_", download_date[i], "_T18LPQ_N0206_R065_T32TMG_", download_date[i], ".SAFE/GRANULE/L1C_T32TMG_A002297_", download_date[i], "/IMG_DATA/T32TMG_20180", format(as.numeric(format(download_date[i], "%j")) + 1, width = 3, justify = "left"), "_B02_10m.jp2")
    
    # load the file and append to the band file
    band_file <- c(band_file, raster(file_name))
  }
  
  # crop the band file
  for (i in 1:length(band_file)){
    crop_band <- crop(band_file[i], extent(c(lon - 0.1, lon + 0.1, lat - 0.1, lat + 0.1)))
    band_file[i]
